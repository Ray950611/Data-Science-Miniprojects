{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The New York Social Graph\n",
    "\n",
    "[New York Social Diary](http://www.newyorksocialdiary.com/) provides a\n",
    "fascinating lens onto New York's socially well-to-do.  The data forms a natural social graph for New York's social elite.  Take a look at this page of a recent [run-of-the-mill holiday party](http://www.newyorksocialdiary.com/party-pictures/2014/holiday-dinners-and-doers).\n",
    "\n",
    "Besides the brand-name celebrities, you will notice the photos have carefully annotated captions labeling those that appear in the photos.  We can think of this as implicitly implying a social graph: there is a connection between two individuals if they appear in a picture together.\n",
    "\n",
    "For this project, we will assemble the social graph from photo captions for parties dated December 1, 2014, and before.  Using this graph, we can make guesses at the most popular socialites, the most influential people, and the most tightly coupled pairs.\n",
    "\n",
    "We will attack the project in three phases:\n",
    "1. Get a list of all the photo pages to be analyzed.\n",
    "2. Parse all of the captions on a sample page.\n",
    "3. Parse all of the captions on all pages, and assemble the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase One\n",
    "\n",
    "The first step is to crawl the data.  We want photos from parties on or before December 1st, 2014.  Go to the [Party Pictures Archive](http://www.newyorksocialdiary.com/party-pictures) to see a list of (party) pages.  We want to get the url for each party page, along with its date.\n",
    "\n",
    "Here are some packagest that you may find useful.  You are welcome to use others, if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import dill\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend using Python [Requests](http://docs.python-requests.org/en/master/) to download the HTML pages, and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) to process the HTML.  Let's start by getting the [first page](http://www.newyorksocialdiary.com/party-pictures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('http://www.newyorksocialdiary.com/party-pictures')# Use requests.get to download the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we process the text of the page with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This page has links to 50 party pages. Look at the structure of the page and determine how to isolate those links.  Your browser's developer tools (usually `Cmd`-`Option`-`I` on Mac, `Ctrl`-`Shift`-`I` on others) offer helpful tools to explore the structure of the HTML page.\n",
    "\n",
    "Once you have found a patter, use BeautifulSoup's [select](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors) or [find_all](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find) methods to get those elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = soup.find('div',{'class': 'view-content'}).find_all('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 50 per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(links) == 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at that first link.  Figure out how to extract the URL of the link, as well as the date.  You probably want to use `datetime.strptime`.  See the [format codes for dates](https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = links[0]\n",
    "# Check that the title and date match what you see visually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of code reuse, let's put that logic into a function.  It should take the link element and return the URL and date parsed from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_link_date(el):\n",
    "    root = 'http://www.newyorksocialdiary.com'\n",
    "    child = str(el.find('a')).split('\"')[1]\n",
    "    url = root+child\n",
    "    date_span = str(el.find_all('span',{'class':'field-content'})[1])\n",
    "    date_str = date_span[int(date_span.find(',')+2):int(date_span.find('<',1))]\n",
    "    date_str = date_str.replace(',','')\n",
    "    date = datetime.strptime(date_str,'%B %d %Y')\n",
    "    return url, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://www.newyorksocialdiary.com/party-pictures/2017/a-grand-affair',\n",
       " datetime.datetime(2017, 12, 28, 0, 0))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_link_date(links[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to check that it works as you expected.\n",
    "\n",
    "Once that's working, let's write another function to parse all of the links on a page.  Thinking ahead, we can make it take a Requests [Response](http://docs.python-requests.org/en/master/api/#requests.Response) object and do the BeautifulSoup parsing within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links(response):\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    links = soup.find('div',{'class': 'view-content'}).find_all('div')\n",
    "    L = []\n",
    "    for link in links:\n",
    "        pair = get_link_date(link)\n",
    "        L.append(pair)\n",
    "    return L # A list of URL, date pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this on the previous response, we should get 50 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(get_links(page)) == 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.newyorksocialdiary.com/party-pictures/2017/a-grand-affair',\n",
       "  datetime.datetime(2017, 12, 28, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/pride-and-self-reliance',\n",
       "  datetime.datetime(2017, 12, 26, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/christmas-cheer',\n",
       "  datetime.datetime(2017, 12, 22, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/reflection-celebration-and-hope',\n",
       "  datetime.datetime(2017, 12, 21, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/adapting-and-achieving',\n",
       "  datetime.datetime(2017, 12, 19, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-dubin-breast-centers-sixth-annual-benefit',\n",
       "  datetime.datetime(2017, 12, 18, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/philanthropy-inclusion-and-refuge',\n",
       "  datetime.datetime(2017, 12, 15, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/help-hope',\n",
       "  datetime.datetime(2017, 12, 13, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/christmas-lights-and-luncheons',\n",
       "  datetime.datetime(2017, 12, 12, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/a-look-around-the-neighborhood',\n",
       "  datetime.datetime(2017, 12, 11, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/initiatives-and-goals',\n",
       "  datetime.datetime(2017, 12, 8, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/second-bloom',\n",
       "  datetime.datetime(2017, 12, 6, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/sound-traditions',\n",
       "  datetime.datetime(2017, 12, 5, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/community-and-opportunity',\n",
       "  datetime.datetime(2017, 11, 30, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/light-years-ahead',\n",
       "  datetime.datetime(2017, 11, 28, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-spirit-of-collaboration',\n",
       "  datetime.datetime(2017, 11, 22, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/blerancourt-awards',\n",
       "  datetime.datetime(2017, 11, 21, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/something-personal',\n",
       "  datetime.datetime(2017, 11, 20, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/game-changers',\n",
       "  datetime.datetime(2017, 11, 17, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/every-day-happenings',\n",
       "  datetime.datetime(2017, 11, 16, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/gatherings-for-good',\n",
       "  datetime.datetime(2017, 11, 15, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/fall-fundraiser-fun',\n",
       "  datetime.datetime(2017, 11, 10, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-devoted-and-divine',\n",
       "  datetime.datetime(2017, 11, 9, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-breast-cancer-alliance-22nd-annual-luncheon-and-fashion-show',\n",
       "  datetime.datetime(2017, 11, 8, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/moving-forward',\n",
       "  datetime.datetime(2017, 11, 7, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/25th-anniversary-jay-soiree',\n",
       "  datetime.datetime(2017, 11, 6, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/new-york-in-full-swing',\n",
       "  datetime.datetime(2017, 11, 3, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/resolution-and-remedy',\n",
       "  datetime.datetime(2017, 10, 31, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/along-for-the-ride',\n",
       "  datetime.datetime(2017, 10, 30, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/stars-on-the-rise',\n",
       "  datetime.datetime(2017, 10, 25, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/behind-the-scenes',\n",
       "  datetime.datetime(2017, 10, 24, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-hearst-castle-preservation-foundations-annual-benefit-weekend',\n",
       "  datetime.datetime(2017, 10, 23, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/scenes-from-the-ballet',\n",
       "  datetime.datetime(2017, 10, 20, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-frick-collection-autumn-dinner',\n",
       "  datetime.datetime(2017, 10, 19, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/lighting-up-lives',\n",
       "  datetime.datetime(2017, 10, 18, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/paying-tribute',\n",
       "  datetime.datetime(2017, 10, 13, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/communications-efforts',\n",
       "  datetime.datetime(2017, 10, 10, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/books-and-birthdays',\n",
       "  datetime.datetime(2017, 10, 5, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/friends-of-the-domaine-de-chantillys-inaugural-gala',\n",
       "  datetime.datetime(2017, 10, 4, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/standing-ovations',\n",
       "  datetime.datetime(2017, 9, 28, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/opening-nights-0',\n",
       "  datetime.datetime(2017, 9, 25, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/champions-for-the-cause',\n",
       "  datetime.datetime(2017, 9, 20, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/hope-and-heroes',\n",
       "  datetime.datetime(2017, 9, 11, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/maison-de-modecom-endless-summer-trunk-show',\n",
       "  datetime.datetime(2017, 9, 1, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/women-artists-maestros-and-keepers-of-the-flame',\n",
       "  datetime.datetime(2017, 8, 31, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/the-league-to-save-lake-tahoe',\n",
       "  datetime.datetime(2017, 8, 25, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/from-newport-to-the-east-end',\n",
       "  datetime.datetime(2017, 8, 23, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/a-weekend-of-festivities-with-the-american-friends-of-the-oxford-philharmonic',\n",
       "  datetime.datetime(2017, 8, 18, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/guild-hall-and-evelyn-alexander',\n",
       "  datetime.datetime(2017, 8, 18, 0, 0)),\n",
       " ('http://www.newyorksocialdiary.com/party-pictures/2017/lovin-long-island',\n",
       "  datetime.datetime(2017, 8, 15, 0, 0))]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we only want parties with dates on or before the first of December, 2014.  Let's write a function to filter our list of dates to those at or before a cutoff.  Using a keyword argument, we can put in a default cutoff, but allow us to test with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_by_date(links, cutoff=datetime(2014, 12, 1)):\n",
    "    filtered_links = []\n",
    "    for link in links:\n",
    "        if link[1]<=cutoff:\n",
    "            filtered_links.append(link)\n",
    "    return filtered_links\n",
    "    # Return only the elements with date <= cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default cutoff, there should be no valid parties on the first page.  Adjust the cutoff date to check that it is actually working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(filter_by_date(get_links(page))) == 0\n",
    "filter_by_date(get_links(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be ready to get all of the party URLs.  Click through a few of the index pages to determine how the URL changes.  Figure out a strategy to visit all of them.\n",
    "\n",
    "HTTP requests are generally IO-bound.  This means that most of the time is spent waiting for the remote server to respond.  If you use `requests` directly, you can only wait on one response at a time.  [requests-futures](https://github.com/ross/requests-futures) lets you wait for multiple requests at a time.  You may wish to use this to speed up the downloading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from requests_futures.sessions import FuturesSession\n",
    "session = FuturesSession()\n",
    "page = session.get('http://www.newyorksocialdiary.com/party-pictures').result()\n",
    "link_list = get_links(page)\n",
    "for i in range(30):\n",
    "    page = session.get('http://www.newyorksocialdiary.com/party-pictures?page='+str(i+1)).result()\n",
    "    link_list.extend(get_links(page))\n",
    "link_list = filter_by_date(link_list)\n",
    "# You can use link_list.extend(others) to add the elements of others\n",
    "# to link_list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, you should have 1193 parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://www.newyorksocialdiary.com/party-pictures/2007/orchids-growing-wild',\n",
       " datetime.datetime(2007, 2, 21, 0, 0))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(link_list) == 1193\n",
    "link_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we need to restart the notebook, we should save this information to a file.  There are many ways you could do this; here's one using `dill`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.dump(link_list, open('nysd-links.pkd', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore the list, we can just load it from the file.  When the notebook is restarted, you can skip the code above and just run this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link_list = dill.load(open('nysd-links.pkd', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: histogram\n",
    "\n",
    "Get the number of party pages for the 95 months (that is, month-year pair) in the data.  Notice that while the party codes might be written as \"FRIDAY, FEBRUARY 28, 2014\", in this output, you would have to represent the month-year code as \"Feb-2014\".  This can all be done with `strftime` and the [format codes for dates](https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior).\n",
    "\n",
    "Plot the histogram for yourself.  Do you see any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEHCAYAAACwUAEWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEoWIiJRSohARkVL/H0KyDF40fWO6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f31397350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "hist_list = []\n",
    "month = []\n",
    "count = []\n",
    "for party in link_list:\n",
    "        date = str(datetime.strftime(party[1],'%b-%Y'))\n",
    "        if date in month:\n",
    "            i = month.index(date)\n",
    "            count[i] +=1\n",
    "            hist_list[i][1]+=1\n",
    "        else:\n",
    "            month.append(date)\n",
    "            hist_list.append([date,1])\n",
    "            count.append(1)\n",
    "\n",
    "y_pos = np.arange(len(month))\n",
    " \n",
    "plt.bar(y_pos, count, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, month)\n",
    "plt.ylabel('Party Counts')\n",
    "plt.title('Party Histogram')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  1.0\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def histogram():\n",
    "    hist_list = []\n",
    "    month = []\n",
    "    for party in link_list:\n",
    "        date = str(datetime.strftime(party[1],'%b-%Y'))\n",
    "        if date in month:\n",
    "            i = month.index(date)\n",
    "            hist_list[i][1]+=1\n",
    "        else:\n",
    "            month.append(date)\n",
    "            hist_list.append([date,1])\n",
    "    return hist_list  # Replace with the correct list\n",
    "\n",
    "grader.score(question_name='graph__histogram', func=histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Two\n",
    "\n",
    "In this phase, we we concentrate on getting the names out of captions for a given page.  We'll start with [the benefit cocktails and dinner](http://www.newyorksocialdiary.com/party-pictures/2015/celebrating-the-neighborhood) for [Lenox Hill Neighborhood House](http://www.lenoxhill.org/), a neighborhood organization for the East Side.\n",
    "\n",
    "Take a look at that page.  Note that some of the text on the page is captions, but others are descriptions of the event.  Determine how to select only the captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('http://www.newyorksocialdiary.com/party-pictures/2015/celebrating-the-neighborhood')\n",
    "soup = BeautifulSoup(page.text, \"lxml\")\n",
    "#title_div = soup.find('div',{'class':'panel-pane pane-page-title'})\n",
    "#title_str = str(title_div.find('h1'))\n",
    "#title = title_str[int(title_str.find('>')+1):int(title_str.find('<',1))]\n",
    "captions = []\n",
    "#captions.append(title)\n",
    "photocaps = soup.find_all('div',{'class':'photocaption'})\n",
    "photocaps.extend(soup.find_all('td',{'class':'photocaption'}))\n",
    "photocaps.extend(soup.find_all('font',{'face':'Verdana, Arial, Helvetica, sans-serif'}))\n",
    "for cap in photocaps:\n",
    "    cap_str = str(cap)\n",
    "    caption = cap_str[int(cap_str.find('>')+1):int(cap_str.find('<',1))]\n",
    "    if len(caption)!=0:\n",
    "        \n",
    "        captions.append(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By our count, there are about 110.  But if you're off by a couple, you're probably okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert abs(len(captions) - 110) < 5\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encapsulate this in a function.  As with the links pages, we want to avoid downloading a given page the next time we need to run the notebook.  While we could save the files by hand, as we did before, a checkpointing library like [ediblepickle](https://pypi.python.org/pypi/ediblepickle/1.1.3) can handle this for you.  (Note, though, that you may not want to enable this until you are sure that your function is working.)\n",
    "\n",
    "You should also keep in mind that HTTP requests fail occasionally, for transient reasons.  You should plan how to detect and react to these failures.   The [retrying module](https://pypi.python.org/pypi/retrying) is one way to deal with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from retrying import retry\n",
    "@retry\n",
    "def get_captions(path):\n",
    "    page = requests.get(str(path))\n",
    "    soup = BeautifulSoup(page.text, \"lxml\")\n",
    "    #title_div = soup.find('div',{'class':'panel-pane pane-page-title'})\n",
    "    #title_str = str(title_div.find('h1'))\n",
    "    #title = title_str[int(title_str.find('>')+1):int(title_str.find('<',1))]\n",
    "    captions = []\n",
    "    #captions.append(title)\n",
    "    photocaps = soup.find_all('div',{'class':'photocaption'})\n",
    "    photocaps.extend(soup.find_all('td',{'class':'photocaption'}))\n",
    "    photocaps.extend(soup.find_all('font',{'face':'Verdana, Arial, Helvetica, sans-serif'}))\n",
    "    for cap in photocaps:\n",
    "        cap_str = str(cap)\n",
    "        caption = cap_str[int(cap_str.find('>')+1):int(cap_str.find('<',1))]\n",
    "        if len(caption)!=0:\n",
    "            captions.append(caption)\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get the same captions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert captions == get_captions(\"http://www.newyorksocialdiary.com/party-pictures/2015/celebrating-the-neighborhood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some sample captions, let's start parsing names out of those captions.  There are many ways of going about this, and we leave the details up to you.  Some issues to consider:\n",
    "\n",
    "  1. Some captions are not useful: they contain long narrative texts that explain the event.  Try to find some heuristic rules to separate captions that are a list of names from those that are not.  A few heuristics include:\n",
    "    - look for sentences (which have verbs) and as opposed to lists of nouns. For example, [nltk does part of speech tagging](http://www.nltk.org/book/ch05.html) but it is a little slow. There may also be heuristics that accomplish the same thing.\n",
    "    - Similarly, spaCy's [entity recognition](https://spacy.io/docs/usage/entity-recognition) couble be useful here.\n",
    "    - Look for commonly repeated threads (e.g. you might end up picking up the photo credits or people such as \"a friend\").\n",
    "    - Long captions are often not lists of people.  The cutoff is subjective, but for grading purposes, *set that cutoff at 250 characters*.\n",
    "  2. You will want to separate the captions based on various forms of punctuation.  Try using `re.split`, which is more sophisticated than `string.split`. **Note**: The reference solution uses regex exclusively for name parsing.\n",
    "  3. You might find a person named \"ra Lebenthal\".  There is no one by this name.  Can anyone spot what's happening here?\n",
    "  4. This site is pretty formal and likes to say things like \"Mayor Michael Bloomberg\" after his election but \"Michael Bloomberg\" before his election.  Can you find other ('optional') titles that are being used?  They should probably be filtered out because they ultimately refer to the same person: \"Michael Bloomberg.\"\n",
    "  5. There is a special case you might find where couples are written as eg. \"John and Mary Smith\". You will need to write some extra logic to make sure this properly parses to two names: \"John Smith\" and \"Mary Smith\".\n",
    "  6. When parsing names from captions, it can help to look at your output frequently and address the problems that you see coming up, iterating until you have a list that looks reasonable. This is the approach used in the reference solution. Because we can only asymptotically approach perfect identification and entity matching, we have to stop somewhere.\n",
    "  \n",
    "**Questions worth considering:**\n",
    "  1. Who is Patrick McMullan and should he be included in the results? How would you address this?\n",
    "  2. What else could you do to improve the quality of the graph's information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "def test_name_format(name_str):\n",
    "    name_l = name_str.split()\n",
    "    first = name_l[0]\n",
    "    last = name_l[-1]\n",
    "    if first.isupper() or last.isupper():\n",
    "        return False\n",
    "    elif first[0].isupper() and last[0].isupper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def parse_text(text_raw,name_list):\n",
    "    try:\n",
    "        text_raw = text_raw.replace('’','')\n",
    "        text_raw = text_raw.replace('”','')\n",
    "        text_raw = text_raw.replace('“','')\n",
    "        text = nltk.tokenize.word_tokenize(text_raw)\n",
    "        #print text\n",
    "        tag_type = nltk.pos_tag(text)\n",
    "\n",
    "        pos = 0\n",
    "        while pos<len(tag_type):\n",
    "            cur = 0\n",
    "            temp_str = ''\n",
    "            cur_pair = tag_type[pos]\n",
    "            flag = False\n",
    "            couple = False\n",
    "            while cur_pair[1]=='NNP' and flag == False and couple==False:\n",
    "                temp_str += cur_pair[0]+' '\n",
    "                cur+=1\n",
    "                if pos+cur<len(tag_type):\n",
    "                    cur_pair = tag_type[pos+cur]\n",
    "                    if cur==1 and cur_pair[0]=='and' and pos+3<len(tag_type):\n",
    "                        next_pair = tag_type[pos+2]\n",
    "                        next_next = tag_type[pos+3]\n",
    "                        if next_pair[1]=='NNP' and next_next[1]=='NNP':\n",
    "                            temp_str = temp_str+next_next[0]+','+next_pair[0]+' '+next_next[0]\n",
    "\n",
    "                            couple=True\n",
    "                else:\n",
    "                    flag = True\n",
    "            if couple:\n",
    "                pos+=4\n",
    "                temp = temp_str.split(',')\n",
    "                temp1 = temp[0]\n",
    "                temp2 = temp[1]\n",
    "                if test_name_format(temp1):\n",
    "                    name = temp1\n",
    "                    if name not in name_list:\n",
    "                        name_list.append(name)\n",
    "                if test_name_format(temp2):\n",
    "                    name = temp2\n",
    "                    if name not in name_list:\n",
    "                        name_list.append(name)\n",
    "            else:\n",
    "                pos+=cur+1\n",
    "                if cur>1 and test_name_format(temp_str):\n",
    "                    name = temp_str[:-1]\n",
    "                    if name not in name_list:\n",
    "                        name_list.append(name)\n",
    "        #print name_list\n",
    "    except ValueError:\n",
    "        pass\n",
    "        #print text_raw\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: sample_names\n",
    "\n",
    "Once you feel that your algorithm is working well on these captions, parse all of the captions and extract all the names mentioned.  Sort them alphabetically, by first name, and return the first hundred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.98\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def sample_names():\n",
    "    names = []\n",
    "    for rawtext in captions:       \n",
    "        parse_text(rawtext,names)    \n",
    "    names.sort()\n",
    "    return names[0:100]\n",
    "\n",
    "grader.score(question_name='graph__sample_names', func=sample_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run this sort of test on a few other pages.  You will probably find that other pages have a slightly different HTML structure, as well as new captions that trip up your caption parser.  But don't worry if the parser isn't perfect -- just try to get the easy cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caption_new =  get_captions('http://www.newyorksocialdiary.com/party-pictures/2017/christmas-lights-and-luncheons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alexandra Lebenthal', 'Alexandra Marshall', 'Alexia Hamm Ryan', 'Alison Mazzola', 'Alyce Faye Cleese', 'Ann Colley', 'Anna Gary', 'Anne Randell', 'Ashley Carlson', 'Barbara McLaughlin', 'Blair Beal', 'Blair Brock', 'Bonnie Pfeifer Evans', 'Brick Church', 'Brick Church Children', 'Brick Presbyterian Church', 'Caroline Dean', 'Christine Rose', 'Club Holiday Luncheon', 'Colette O. Bryce Miller', 'Danielle Ganick', 'Davis Colley', 'Dennis Basso', 'Donna Rosen', 'Douglas T. King', 'Eileen Judell', 'Elaine Langone', 'Eleanora Kennedy', 'Ellie Silverman', 'Fred Castleberry', 'Geoffrey Bradfield', 'Georgina Schaeffer', 'Gigi Bacon', 'Greg McCarthy', 'Heather Sargent', 'Jack Fowler', 'Jack Lynch', 'Jackie Yale', 'Jacqueline Gregg', 'Jamee Gregory', 'Jay Santoro', 'Jenny Paulsen', 'Jessica Post', 'Jill Roosevelt', 'Joan Schnitzer', 'Joanne Evans Burns', 'John Klopp', 'Josh Bell', 'Julie Fowler', 'June Shor', 'Kamie Lightburn', 'Kara Sorento', 'Karen Klopp', 'Kate Lynch', 'Katherine Grossman', 'Katherine Williams', 'Keith Toth', 'Knickerbocker Grey Cadets', 'Leba Sedaka', 'Libby Fitzgerald', 'Lisa Simonsen', 'Liz Peek', 'Maria Fishell', 'Mark Gilbertson', 'Mary Davidson', 'Mary Ellen Coyne', 'Maryellen Cundey', 'Melinda Nelson', 'Mika Sterling', 'Mikel Wittle', 'Molly Froelich', 'Neda Navab', 'Nikki Harris', 'Nina Griscom', 'Paige Rustum', 'Park Avenue', 'Park Avenue Trees', 'Patricia Burnham Brock', 'Peter Bickford', 'Polly Onet', 'Regis Warsoe', 'Rick Miller', 'Suzie Aijala Dixie Deluca', 'Teddy Taylor', 'Tory Burch', 'Webb Egerton', 'Wendy Carduner', 'William Brock']\n"
     ]
    }
   ],
   "source": [
    "names_new = []\n",
    "for rawtext in caption_new:       \n",
    "    parse_text(rawtext,names_new)    \n",
    "names_new.sort()\n",
    "print names_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Three\n",
    "\n",
    "Once you are satisfied that your caption scraper and parser are working, run this for all of the pages.  If you haven't implemented some caching of the captions, you probably want to do this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ASF President Edward P. Gallagher, Honoree Monika A. Heimbold, with Gala Chairs Rabby and Kristján Ragnarsson, ASF Board Chair Bente Svensen Frantz, First Lady of Iceland Dorrit Moussaieff, and H.E. Ólafur Ragnar Grímsson, President of Iceland \n",
      "Gala Vice-Chair Joanna Heimbold (left) greets Gala Chairs Dr. Kristján and Rabby Ragnarsson\n",
      " ASF President Edward P. Gallagher, Honoree Monika A. Heimbold, with Gala Chairs Rabby and Kristján Ragnarsson, ASF Board Chair Bente Svensen Frantz, First Lady of Iceland Dorrit Moussaieff, and H.E. Ólafur Ragnar Grímsson, President of Iceland \n",
      " Gala Vice-Chair Joanna Heimbold with Gala Chairs Dr. Kristján and Rabby Ragnarsson \n",
      "Dr.  Paul Meyers and Martha Glass \n",
      "The Park Avenue Armory during Purim Ball 2013: Who Wears the Crown?  Décor by David Stark Design and Production\n",
      "Ms. Michèle Archambault and Jack McCord\n",
      " Natalie Serse, Hotel de Point; Denise DiFranco, Marco LaGuardia Hotel; Tim McGlinchey, Courtyard Marriott JFK; Carl Goodman, Museum of the Moving Image; Letizia Barbetta, Magna Ristorante; Renee Schacht, The Noguchi Museum; Darcy Hector, Queens Botanical Garden; Ernesto Freire, NYC &amp; Company; Assemblywoman Markey; Edwin Martinez, Expedia Lodging Partner Services; and Jennifer Walden, Armstrong House. Nancy A. Conde, chief of staff for State Sen. José R. Peralta was also in attendance.\t         (photo: Rob MacKay).\n",
      " Chair Sloan Overstrom, Jaime E. Jiménez of Baccarat, Chair Clare McKeon \n",
      "Jonathan T. Deland,  M.D., Hannah Yu, Peter Fabricant, and Emme Levin Deland\n",
      " Mr. and Mrs. Charlélie Couture and friend \n",
      " Dr. Robert I. Grossman,  Dr. Silvia Formenti, and Kenneth Langone \n",
      "Sila M. Calderón  and Luis A. Ubiñas \n",
      "Holcomb B. Noble (left), a double Pulitzer Prize-winning journalist and founding board member of the YPC, is honored with the YPCs Humanitarian Award presented by Vice Chairman George Nemeth (center) and the choruss Founder and Artistic Director Francisco J. Núñez.\n",
      "Carl Anderson, director of administration of the Statue of Liberty/Ellis Island Foundation, with YPC Artistic Director/Founder Francisco J. Núñez.\n",
      "Francisco J. Núñez with Adam Chin, and his daughter, chorister Hannah Chinn looks on\n",
      "YPC artistic advisor Linda Golding and Francisco J. Núñez\n",
      "Photographs by ©D. Finnin, R. Micken, C. Chesek (AMNH); ©PatrickMcMullan.com (Roccoco).\n",
      "\n",
      "              Consul General of the Federal Republic of Germany, Mr. and Mrs. Hans-Jürgen Heimsoeth; Christian Zacharias, pianist; Tanja Dorn; and Paul Moravec, composer\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for event in link_list:\n",
    "    link = str(event[0])\n",
    "    cur_caption = get_captions(link)\n",
    "    cur_names = []\n",
    "    for rawtext in cur_caption:    \n",
    "        parse_text(rawtext,cur_names)    \n",
    "    cur_names.sort()\n",
    "    data_list.append((cur_caption,cur_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dill.dump(data_list, open('nysd-data.pkd', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1193"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = dill.load(open('nysd-data.pkd', 'r'))\n",
    "len(data_list)# Scraping all of the pages could take 10 minutes or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_people = []\n",
    "for event in data_list:\n",
    "    names = event[1]\n",
    "    \n",
    "    all_people.extend(names)\n",
    "all_people = pd.unique(all_people).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_captions = []\n",
    "for event in data_list:\n",
    "    caps = event[0]\n",
    "    all_captions.extend(caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103210\n",
      "102863\n"
     ]
    }
   ],
   "source": [
    "print len(all_captions)\n",
    "print len(all_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining analysis, we think of the problem in terms of a\n",
    "[network](http://en.wikipedia.org/wiki/Computer_network) or a\n",
    "[graph](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29).  Any time a pair of people appear in a photo together, that is considered a link.  What we have described is more appropriately called an (undirected)\n",
    "[multigraph](http://en.wikipedia.org/wiki/Multigraph) with no self-loops but this has an obvious analog in terms of an undirected [weighted graph](http://en.wikipedia.org/wiki/Graph_%28mathematics%29#Weighted_graph).  In this problem, we will analyze the social graph of the new york social elite.  We recommend using python's [networkx](https://networkx.github.io/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools  # itertools.combinations may be useful\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "for name in all_people:\n",
    "    G.add_node(name)\n",
    "for cap in all_captions:\n",
    "    names = []\n",
    "    parse_text(cap,names)\n",
    "    n = len(names)\n",
    "    if n>1:\n",
    "        i = 0\n",
    "        \n",
    "        while i<n:\n",
    "            j = i+1\n",
    "            a = names[i]\n",
    "            while j<n:\n",
    "                b = names[j]\n",
    "                if b in G.edge[a].keys():\n",
    "                    G.edge[a][b]['weight']+=1\n",
    "                else:\n",
    "                    G.add_edge(names[i],names[j],weight = 1)\n",
    "                j+=1\n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, you should end up with over 100,000 captions and more than 110,000 names, connected in about 200,000 pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: degree\n",
    "\n",
    "The simplest question to ask is \"who is the most popular\"?  The easiest way to answer this question is to look at how many connections everyone has.  Return the top 100 people and their degree.  Remember that if an edge of the graph has weight 2, it counts for 2 in the degree.\n",
    "\n",
    "**Checkpoint:** Some aggregate stats on the solution\n",
    "\n",
    "    \"count\": 100.0\n",
    "    \"mean\": 189.92\n",
    "    \"std\": 87.8053034454\n",
    "    \"min\": 124.0\n",
    "    \"25%\": 138.0\n",
    "    \"50%\": 157.0\n",
    "    \"75%\": 195.0\n",
    "    \"max\": 666.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 659.  502.  378.  371.  302.  297.  295.  287.  287.  285.  284.  280.\n",
      "  261.  255.  250.  247.  246.  239.  236.  228.  227.  223.  213.  210.\n",
      "  210.  209.  200.  196.  196.  192.  191.  186.  184.  182.  181.  176.\n",
      "  176.  175.  175.  174.  172.  172.  172.  172.  171.  169.  167.  166.\n",
      "  166.  166.  165.  162.  161.  160.  159.  158.  156.  156.  154.  152.\n",
      "  151.  151.  150.  149.  148.  148.  147.  146.  146.  145.  144.  144.\n",
      "  144.  143.  142.  142.  141.  139.  137.  136.  134.  133.  133.  132.\n",
      "  131.  131.  131.  131.  130.  129.  128.  128.  127.  127.  126.  126.\n",
      "  125.  124.  124.  123.]\n"
     ]
    }
   ],
   "source": [
    "dic = nx.degree(G,weight='weight')\n",
    "dic = sorted(dic.items(), key=lambda x: (-x[1], x[0]))\n",
    "most_pop = dic[0:100]\n",
    "dataset = np.zeros(100)\n",
    "for i in range(100):\n",
    "    dataset[i] = int(most_pop[i][1])\n",
    "print dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.94\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "import heapq  # Heaps are efficient structures for tracking the largest\n",
    "              # elements in a collection.  Use introspection to find the\n",
    "              # function you need.\n",
    "def degree():\n",
    "    dic = nx.degree(G,weight='weight')\n",
    "    dic = sorted(dic.items(), key=lambda x: (-x[1], x[0]))\n",
    "    most_pop = dic[0:100]\n",
    "    \n",
    "    return most_pop\n",
    "\n",
    "grader.score(question_name='graph__degree', func=degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: pagerank\n",
    "\n",
    "A similar way to determine popularity is to look at their\n",
    "[pagerank](http://en.wikipedia.org/wiki/PageRank).  Pagerank is used for web ranking and was originally\n",
    "[patented](http://patft.uspto.gov/netacgi/nph-Parser?patentnumber=6285999) by Google and is essentially the stationary distribution of a [markov\n",
    "chain](http://en.wikipedia.org/wiki/Markov_chain) implied by the social graph.\n",
    "\n",
    "Use 0.85 as the damping parameter so that there is a 15% chance of jumping to another vertex at random.\n",
    "\n",
    "**Checkpoint:** Some aggregate stats on the solution\n",
    "\n",
    "    \"count\": 100.0\n",
    "    \"mean\": 0.0001841088\n",
    "    \"std\": 0.0000758068\n",
    "    \"min\": 0.0001238355\n",
    "    \"25%\": 0.0001415028\n",
    "    \"50%\": 0.0001616183\n",
    "    \"75%\": 0.0001972663\n",
    "    \"max\": 0.0006085816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jean Shafiroff', 0.0006398105053257939), ('Mark Gilbertson', 0.0004986854560301254), ('Geoffrey Bradfield', 0.0003771351579715255), ('Alexandra Lebenthal', 0.00034150430389995735), ('Executive Director', 0.00033462449151331974), ('Andrew Saffir', 0.0003196149563592893), ('Sharon Bush', 0.0002976681080805016), ('New York', 0.00029649922774886624), ('Yaz Hernandez', 0.00029039820039654813), ('Mario Buatta', 0.00028202380684940815), ('Kamie Lightburn', 0.0002773965292017132), ('Debbie Bancroft', 0.00027676754425296494), ('Barbara Tober', 0.0002522033819654341), ('Eleanora Kennedy', 0.00025116324541135535), ('Alina Cho', 0.00024935811491181886), ('Gillian Miniter', 0.00024411006319350752), ('Lucia Hwong Gordon', 0.00024378973747270409), ('Lydia Fenet', 0.0002421152492706765), ('Christopher Hyland', 0.0002290930201486151), ('Patrick McMullan', 0.0002250016032892288), ('Bonnie Comley', 0.00022342005048121152), ('Jamee Gregory', 0.00021653966538934998), ('Allison Aston', 0.00021505278705822307), ('Bettina Zilkha', 0.00020978150487607706), ('Muffie Potter Aston', 0.0002092304997650892), ('Deborah Norville', 0.00020815044278811977), ('Dayssi Olarte', 0.00020069559443753633), ('Martha Stewart', 0.00019858177879723585), ('Somers Farkas', 0.00019811157829498303), ('Michele Herbert', 0.00019766006644318963), ('Karen LeFrak', 0.0001972900284105061), ('Elizabeth Stribling', 0.00019601899120726398), ('Special Surgery', 0.00019288108722819727), ('Fernanda Kellogg', 0.00019207842862813823), ('Kipton Cronkite', 0.00018752172481347458), ('Leonard Lauder', 0.0001864030595210374), ('Donna Karan', 0.00018583984464715905), ('Amy Fine Collins', 0.00018500288434036388), ('Daniel Benedict', 0.0001832535053232441), ('Karen Klopp', 0.00018105060226301478), ('Grace Meigher', 0.00017923582393315822), ('Diana Taylor', 0.00017780997378354066), ('Evelyn Lauder', 0.00017680888181167905), ('Steven Stolman', 0.00017629218381140383), ('Russell Simmons', 0.00017554006169138346), ('Liliana Cavendish', 0.0001721121813164403), ('Mayor Michael Bloomberg', 0.00017187789991062743), ('Nicole Miller', 0.00017173354557664525), ('Liz Peek', 0.00017124445324804636), ('Barbara Regna', 0.00016998972788288624), ('Alec Baldwin', 0.00016961184586126058), ('Stewart Lane', 0.00016925113332560794), ('Margo Langenberg', 0.0001688471781618261), ('Audrey Gruss', 0.00016610889339429034), ('Dawne Marie Grannum', 0.0001656196138555976), ('Richard Johnson', 0.00016471735588374998), ('Anka Palitz', 0.0001643216181670266), ('Roric Tobin', 0.0001634651053512073), ('Jennifer Creel', 0.0001605974104041803), ('Amy McFarland', 0.0001598339993419733), ('Bette Midler', 0.00015963395012049043), ('Paula Zahn', 0.00015866563940433425), ('Gregory Long', 0.00015829303048598803), ('Dennis Basso', 0.00015802163418225133), ('Fern Mallis', 0.00015644181268245107), ('Michele Gerber Klein', 0.00015604625734459042), ('Rosanna Scotto', 0.00015601275286796117), ('Susan Shin', 0.00015593114647533912), ('Lisa Anastos', 0.00015310138618007405), ('Nathalie Kaplan', 0.0001516714756639999), ('Board Member', 0.00014768414891724594), ('Prince Dimitri', 0.00014643982147678246), ('Fe Fendi', 0.00014622482450163694), ('Pamela Fiori', 0.00014622114213924559), ('Tory Burch', 0.00014548272999963244), ('Consul General', 0.00014543243296761882), ('Amy Hoadley', 0.00014401568464467735), ('Cynthia Lufkin', 0.0001424962187331971), ('Coco Kopelman', 0.00014166365443356953), ('Adelina Wong Ettelson', 0.00014163588079953997), ('Margo Catsimatidis', 0.0001401195878038463), ('Susan Magazine', 0.0001400691925579523), ('Janna Bullock', 0.00013963259332095085), ('Georgina Schaeffer', 0.0001395511799304443), ('David Koch', 0.00013946632978255894), ('Tina Brown', 0.00013887079143687692), ('Tinsley Mortimer', 0.0001388002802386971), ('Felicia Taylor', 0.00013839539290659857), ('CeCe Black', 0.00013747078101645425), ('Alexandra Lind Rose', 0.0001359361044258126), ('Jamie Niven', 0.00013577228199661184), ('Jill Zarin', 0.0001354875000604763), ('Cassandra Seidenfeld', 0.00013486613479407922), ('Martha Glass', 0.00013442638927782443), ('Denise Rich', 0.0001335116356849744), ('Karen Pearl', 0.00013311039383701937), ('Edward Callaghan', 0.00013133418842547895), ('Margaret Russell', 0.00013089219379064745), ('Mary Van Pelt', 0.00013087411374959618), ('Peter Lyden', 0.00013041618751921384)]\n"
     ]
    }
   ],
   "source": [
    "result = nx.pagerank(G,alpha=0.85)\n",
    "result = sorted(result.items(), key=lambda x: (-x[1], x[0]))[0:100]\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.93\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def pagerank():\n",
    "    result = nx.pagerank(G,alpha=0.85)\n",
    "\n",
    "    result = sorted(result.items(), key=lambda x: (-x[1], x[0]))[0:100]\n",
    "    return result\n",
    "\n",
    "grader.score(question_name='graph__pagerank', func=pagerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: best_friends\n",
    "\n",
    "Another interesting question is who tend to co-occur with each other.  Give us the 100 edges with the highest weights.\n",
    "\n",
    "Google these people and see what their connection is.  Can we use this to detect instances of infidelity?\n",
    "\n",
    "**Checkpoint:** Some aggregate stats on the solution\n",
    "\n",
    "    \"count\": 100.0\n",
    "    \"mean\": 25.84\n",
    "    \"std\": 16.0395470855\n",
    "    \"min\": 14.0\n",
    "    \"25%\": 16.0\n",
    "    \"50%\": 19.0\n",
    "    \"75%\": 29.25\n",
    "    \"max\": 109.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Bonnie Comley', 'Stewart Lane'), 76), (('Peter Gregory', 'Jamee Gregory'), 74), (('Geoffrey Bradfield', 'Roric Tobin'), 67), (('Andrew Saffir', 'Daniel Benedict'), 65), (('Donald Tober', 'Barbara Tober'), 57), (('Jay Diamond', 'Alexandra Lebenthal'), 51), (('Gillian Miniter', 'Sylvester Miniter'), 50), (('Jean Shafiroff', 'Martin Shafiroff'), 48), (('Grace Meigher', 'Chris Meigher'), 44), (('Michael Kennedy', 'Eleanora Kennedy'), 42), (('Sessa von Richthofen', 'Richard Johnson'), 41), (('Margo Catsimatidis', 'John Catsimatidis'), 40), (('Peter Regna', 'Barbara Regna'), 39), (('Jonathan Tisch', 'Lizzie Tisch'), 39), (('Yaz Hernandez', 'Valentin Hernandez'), 38), (('Elizabeth Stribling', 'Guy Robinson'), 38), (('Somers Farkas', 'Jonathan Farkas'), 37), (('Deborah Norville', 'Karl Wellner'), 35), (('Hilary Geary Ross', 'Wilbur Ross'), 34), (('David Koch', 'Julia Koch'), 34), (('Fernanda Kellogg', 'Kirk Henckels'), 34), (('Frederick Anderson', 'Douglas Hannant'), 31), (('Campion Platt', 'Tatiana Platt'), 31), (('Coco Kopelman', 'Arie Kopelman'), 30), (('Anne Hearst McInerney', 'Jay McInerney'), 29), (('Dan Lufkin', 'Cynthia Lufkin'), 28), (('Michael Cominotto', 'Dennis Basso'), 27), (('Arlene Dahl', 'Marc Rosen'), 26), (('Leonel Piraino', 'Nina Griscom'), 26), (('Clo Cohen', 'Charles Cohen'), 25), (('Mark Badgley', 'James Mischka'), 25), (('Tommy Hilfiger', 'Dee Ocleppo'), 24), (('Chuck Scarborough', 'Ellen Scarborough'), 24), (('Melania Trump', 'Donald Trump'), 24), (('Wilbur Ross', 'Hilary Ross'), 23), (('Liz Peek', 'Jeff Peek'), 22), (('Judy Gilbert', 'Rod Gilbert'), 21), (('Al Roker', 'Deborah Roberts'), 21), (('David Lauren', 'Lauren Bush'), 21), (('Rick Friedberg', 'Francine LeFrak'), 21), (('Stephanie Krieger', 'Brian Stewart'), 20), (('Richard Steinberg', 'Renee Steinberg'), 20), (('Sharon Bush', 'Jean Shafiroff'), 20), (('Marvin Davidson', 'Mary Davidson'), 20), (('Harry Slatkin', 'Laura Slatkin'), 20), (('Milstein Hall', 'Ocean Life'), 20), (('Donna Soloway', 'Richard Soloway'), 20), (('Coleman Burke', 'Susan Burke'), 19), (('Rick Hilton', 'Kathy Hilton'), 19), (('Olivia Palermo', 'Johannes Huebl'), 19), (('Othon Prounis', 'Kathy Prounis'), 19), (('Anna Safir', 'Eleanora Kennedy'), 19), (('Alina Cho', 'John Demsey'), 18), (('Hunt Slonem', 'Liliana Cavendish'), 18), (('Jean Shafiroff', 'Patricia Shiah'), 18), (('Bobby Zarin', 'Jill Zarin'), 18), (('CeCe Black', 'Lee Black'), 18), (('Nicole Miller', 'Kim Taipale'), 18), (('Thorne Perkin', 'Tatiana Perkin'), 18), (('Susan Magazine', 'Nicholas Scoppetta'), 18), (('Tony Ingrao', 'Randy Kemper'), 17), (('Naeem Khan', 'Ranjana Khan'), 17), (('Isabel Toledo', 'Ruben Toledo'), 17), (('John Wambold', 'Melanie Wambold'), 17), (('Bunny Williams', 'John Rosselli'), 16), (('Michele Herbert', 'Larry Herbert'), 16), (('Keytt Lundqvist', 'Alex Lundqvist'), 16), (('John K. Castle', 'Dr. John J. Connolly'), 16), (('Melissa Morris', 'Chappy Morris'), 16), (('Alec Baldwin', 'Hilaria Baldwin'), 16), (('Robert Bradford', 'Barbara Taylor Bradford'), 16), (('Harry Kargman', 'Jill Kargman'), 15), (('Arnie Rosenshein', 'Paola Rosenshein'), 15), (('Marisol Thomas', 'Rob Thomas'), 15), (('Marcia Mishaan', 'Richard Mishaan'), 15), (('Bonnie Comley', 'Leah Lane'), 15), (('Karen LeFrak', 'Richard LeFrak'), 15), (('Whitney Fairchild', 'James Fairchild'), 15), (('Jean Shafiroff', 'Lucia Hwong Gordon'), 15), (('Mary Snow', 'Ian Snow'), 15), (('Cece Black', 'Lee Black'), 15), (('Shirin von Wulffen', 'Frederic Fekkai'), 15), (('Edwina Sandys', 'Richard Kaplan'), 14), (('Nick Korniloff', 'Pamela Cohen'), 14), (('Andrea DuBois', 'Maurice DuBois'), 14), (('American Museum', 'Natural History'), 14), (('Samantha Yanks', 'David Yanks'), 14), (('Edward Callaghan', 'John Wegorzewski'), 14), (('Charlotte Ronson', 'Ali Wise'), 14), (('Elaine Langone', 'Ken Langone'), 14), (('Andrew Right', 'Zibby Right'), 14), (('Geoffrey Thomas', 'Sharon Sondes'), 14), (('Roxanne Palin', 'Dean Palin'), 14), (('Ann Rapp', 'Roy Kean'), 14), (('Philip Gorrivan', 'Lisa Gorrivan'), 14), (('Delfina Blaquier', 'Nacho Figueras'), 13), (('Larry Wohl', 'Leesa Rowland'), 13), (('Darci Kistler', 'Peter Martins'), 13), (('Chuck Royce', 'Deborah Royce'), 13), (('Ken Starr', 'Diane Passage'), 13)]\n"
     ]
    }
   ],
   "source": [
    "count_list = []\n",
    "for e in G.edges():\n",
    "    weight = G.edge[e[0]][e[1]]['weight']\n",
    "    count_list.append(((e[0],e[1]),weight))\n",
    "pairs = sorted(count_list,key = lambda x:x[1],reverse=True)[0:100]\n",
    "print pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score:  0.94\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "def best_friends():\n",
    "    count_list = []\n",
    "    for e in G.edges():\n",
    "        weight = G.edge[e[0]][e[1]]['weight']\n",
    "        count_list.append(((e[0],e[1]),weight))\n",
    "    pairs = sorted(count_list,key = lambda x:x[1],reverse=True)[0:100]\n",
    "    return pairs\n",
    "\n",
    "grader.score(question_name='graph__best_friends', func=best_friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
